{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from diffusion_utilities import *\n",
    "from contextUnet import ContextUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "# diffusion hyperparameters\n",
    "timesteps = 500\n",
    "beta1 = 1e-4\n",
    "beta2 = 0.02\n",
    "\n",
    "# network hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else torch.device('cpu'))\n",
    "n_feat = 64 # 64 hidden dimension feature\n",
    "n_cfeat = 5 # context vector is of size 5\n",
    "height = 16 # 16x16 image\n",
    "save_dir = './weights/'\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 100\n",
    "n_epoch = 32\n",
    "lrate=1e-3\n",
    "\n",
    "# construct DDPM noise schedule\n",
    "b_t = (beta2 - beta1) * torch.linspace(0, 1, timesteps + 1, device=device) + beta1\n",
    "a_t = 1 - b_t\n",
    "ab_t = torch.cumsum(a_t.log(), dim=0).exp()    \n",
    "ab_t[0] = 1\n",
    "\n",
    "# construct model\n",
    "nn_model = ContextUnet(in_channels=3, n_feat=n_feat, n_cfeat=n_cfeat, height=height).to(device)\n",
    "\n",
    "# re setup optimizer\n",
    "optim = torch.optim.Adam(nn_model.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: perturbs an image to a specified noise level\n",
    "def perturb_input(x, t, noise):\n",
    "    return ab_t.sqrt()[t, None, None, None] * x + (1 - ab_t[t, None, None, None]) * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sprite shape: (89400, 16, 16, 3)\n",
      "labels shape: (89400, 5)\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:58<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_0.pth\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:56<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:56<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:56<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:05<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_4.pth\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:05<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_8.pth\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:03<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:03<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_12.pth\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:04<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:57<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_16.pth\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:55<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:01<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:02<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:01<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_20.pth\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:58<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:01<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:03<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:00<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_24.pth\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:01<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:02<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:00<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [01:00<00:00, 14.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_28.pth\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:58<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:57<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [00:58<00:00, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./weights/context_model_31.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(\"./data/sprites_1788_16x16.npy\", \"./data/sprite_labels_nc_1788_16x16.npy\", transform, null_context=False)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# training with context code\n",
    "# set into train mode\n",
    "nn_model.train()\n",
    "\n",
    "for ep in range(n_epoch):\n",
    "    print(f'epoch {ep}')\n",
    "    \n",
    "    # linearly decay learning rate\n",
    "    optim.param_groups[0]['lr'] = lrate*(1-ep/n_epoch)\n",
    "    \n",
    "    pbar = tqdm(dataloader, mininterval=2 )\n",
    "    for x, c in pbar:   # x: images  c: context\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        c = c.to(x)\n",
    "        \n",
    "        # randomly mask out c\n",
    "        context_mask = torch.bernoulli(torch.zeros(c.shape[0]) + 0.9).to(device)\n",
    "        c = c * context_mask.unsqueeze(-1)\n",
    "        \n",
    "        # perturb data\n",
    "        noise = torch.randn_like(x)\n",
    "        t = torch.randint(1, timesteps + 1, (x.shape[0],)).to(device) \n",
    "        x_pert = perturb_input(x, t, noise)\n",
    "        \n",
    "        # use network to recover noise\n",
    "        pred_noise = nn_model(x_pert, t / timesteps, c=c)\n",
    "        \n",
    "        # loss is mean squared error between the predicted and true noise\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "\n",
    "    # save model periodically\n",
    "    if ep%4==0 or ep == int(n_epoch-1):\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        torch.save(nn_model.state_dict(), save_dir + f\"context_model_{ep}.pth\")\n",
    "        print('saved model at ' + save_dir + f\"context_model_{ep}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function; removes the predicted noise (but adds some noise back in to avoid collapse)\n",
    "def denoise_add_noise(x, t, pred_noise, z=None):\n",
    "    if z is None:\n",
    "        z = torch.randn_like(x)\n",
    "    noise = b_t.sqrt()[t] * z\n",
    "    mean = (x - pred_noise * ((1 - a_t[t]) / (1 - ab_t[t]).sqrt())) / a_t[t].sqrt()\n",
    "    return mean + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample with context using standard algorithm\n",
    "@torch.no_grad()\n",
    "def sample_ddpm_context(n_sample, context, save_rate=20):\n",
    "    # x_T ~ N(0, 1), sample initial noise\n",
    "    samples = torch.randn(n_sample, 3, height, height).to(device)  \n",
    "\n",
    "    # array to keep track of generated steps for plotting\n",
    "    intermediate = [] \n",
    "    for i in range(timesteps, 0, -1):\n",
    "        print(f'sampling timestep {i:3d}', end='\\r')\n",
    "\n",
    "        # reshape time tensor\n",
    "        t = torch.tensor([i / timesteps])[:, None, None, None].to(device)\n",
    "\n",
    "        # sample some random noise to inject back in. For i = 1, don't add back in noise\n",
    "        z = torch.randn_like(samples) if i > 1 else 0\n",
    "\n",
    "        eps = nn_model(samples, t, c=context)    # predict noise e_(x_t,t, ctx)\n",
    "        samples = denoise_add_noise(samples, i, eps, z)\n",
    "        if i % save_rate==0 or i==timesteps or i<8:\n",
    "            intermediate.append(samples.detach().cpu().numpy())\n",
    "\n",
    "    intermediate = np.stack(intermediate)\n",
    "    return samples, intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(imgs, nrow=2):\n",
    "    _, axs = plt.subplots(nrow, imgs.shape[0] // nrow, figsize=(4,2 ))\n",
    "    axs = axs.flatten()\n",
    "    for img, ax in zip(imgs, axs):\n",
    "        img = (img.permute(1, 2, 0).clip(-1, 1).detach().cpu().numpy() + 1) / 2\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling timestep   1\r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mix of defined context\n",
    "ctx = torch.tensor([\n",
    "    # hero, non-hero, food, spell, side-facing\n",
    "    [1,0,0,0,0],      #human\n",
    "    [1,0,0.6,0,0],    \n",
    "    [0,0,0.6,0.4,0],  \n",
    "    [1,0,0,0,1],  \n",
    "    [1,1,0,0,0],\n",
    "    [1,0,0,1,0]\n",
    "]).float().to(device)\n",
    "samples, _ = sample_ddpm_context(ctx.shape[0], ctx)\n",
    "show_images(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
